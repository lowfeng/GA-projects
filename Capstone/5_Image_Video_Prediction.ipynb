{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5_Image_Video_Prediction.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMnZwOc39BTWP1QC9nWFCSd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"XiIxIwUGeaC6"},"source":["# Video Playback Detection\n","\n","Source Code is adapted from [here](https://learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/)"]},{"cell_type":"markdown","metadata":{"id":"2xgjgJdDevKP"},"source":["# Mount Google Drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uR03qQSLh4rC","executionInfo":{"status":"ok","timestamp":1636569975419,"user_tz":-480,"elapsed":28893,"user":{"displayName":"Low Feng Gabriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02805359518869888109"}},"outputId":"15feb09e-7c94-4028-8c09-4c076b694e44"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"OVUkc356fA7w"},"source":["# Import Libraries"]},{"cell_type":"code","metadata":{"id":"v13YcbACm6hc","executionInfo":{"status":"ok","timestamp":1636569982033,"user_tz":-480,"elapsed":3574,"user":{"displayName":"Low Feng Gabriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02805359518869888109"}}},"source":["\n","import numpy as np\n","import cv2\n","from google.colab.patches import cv2_imshow    # cv.imshow() is known to crash Google Colab notebooks. This is the alternative suggested by Colab.\n","import os\n","from tensorflow.keras.models import load_model"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HeqUzsUsfE1f"},"source":["# Load Age and Gender models"]},{"cell_type":"code","metadata":{"id":"g6vFaufemq8C","executionInfo":{"status":"ok","timestamp":1636569991765,"user_tz":-480,"elapsed":9753,"user":{"displayName":"Low Feng Gabriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02805359518869888109"}}},"source":["# Getting the trained CNN model from the source link.\n","#!wget -qq \"https://drive.google.com/drive/folders/1-2HxPUcCTdV0InQeJG3rFWOxp_xF7sm0?usp=sharing\" -O \"final_cnn_model_checkpoint.h5\"\n","\n","# Loading the trained CNN model for age classification, and defining a list of age-ranges as defined in the model.\n","age_model = load_model(\"/content/drive/MyDrive/Colab Notebooks/models/age/final_age_model_checkpoint_7403.h5\")\n","age_ranges = ['0-1','2-4','5-12','13-19','20-39','50-69','60-116']\n","\n","gender_model = load_model(\"/content/drive/MyDrive/Age_Classification_with_Faces/input_output/gender_cnn_1_checkpoint.h5\")\n","gender_ranges = ['MALE','FEMALE']"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AlhaDgv2fLuq"},"source":["# Load Face Detection Model \n","\n","we will be using the Haarcascade_frontalface model"]},{"cell_type":"code","metadata":{"id":"-Qr1tvB3p-WO","executionInfo":{"status":"ok","timestamp":1636570002025,"user_tz":-480,"elapsed":508,"user":{"displayName":"Low Feng Gabriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02805359518869888109"}}},"source":["\n","\n","# Getting the trained CNN model from the source link.\n","#!wget -qq \"https://drive.google.com/uc?export=download&id=1Gcz4wc8iA1SHfV9REcK4i74Tf9vaETq7\" -O \"haarcascade_frontalface_default.xml\"\n","\n","# Importing the Haar Cascades classifier XML file.\n","face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BpydpgP8fUVp"},"source":["# Function to detect face and use model to predict"]},{"cell_type":"code","metadata":{"id":"K5vxqsHCp-D9","executionInfo":{"status":"ok","timestamp":1636571432262,"user_tz":-480,"elapsed":1413,"user":{"displayName":"Low Feng Gabriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02805359518869888109"}}},"source":["\n","# Defining a function to shrink the detected face region by a scale for better prediction in the model.\n","\n","def shrink_face_roi(x, y, w, h, scale=0.9):\n","    wh_multiplier = (1-scale)/2\n","    x_new = int(x + (w * wh_multiplier))\n","    y_new = int(y + (h * wh_multiplier))\n","    w_new = int(w * scale)\n","    h_new = int(h * scale)\n","    return (x_new, y_new, w_new, h_new)\n","\n","\n","# Defining a function to create the predicted age overlay on the image by centering the text.\n","\n","def create_age_text(img, age, pct_age, gender, pct_gender, x, y, w, h):\n","\n","    # Defining font, scales and thickness.\n","    fontFace = cv2.FONT_HERSHEY_SIMPLEX\n","    age_scale = 1.0\n","    pct_age_scale = 0.50\n","    gender_scale = 1.0\n","    pct_gender_scale = 0.50\n","\n","    # Getting width, height and baseline of age text and \"years old\".\n","    (age_width, age_height), age_bsln = cv2.getTextSize(age, fontFace=fontFace, fontScale=age_scale, thickness=2)\n","    (pct_age_width, pct_age_height), pct_age_bsln = cv2.getTextSize(pct_age, fontFace=fontFace, fontScale=pct_age_scale, thickness=1)\n","    (gender_width, gender_height), gender_bsln = cv2.getTextSize(gender, fontFace=fontFace, fontScale=gender_scale, thickness=2)\n","    (pct_gender_width, pct_gender_height), pct_gender_bsln = cv2.getTextSize(pct_gender, fontFace=fontFace, fontScale=pct_gender_scale, thickness=1)\n","\n","\n","    # Calculating center point coordinates of text background rectangle.\n","    x_center = x + (w/2)\n","    y_age_center = y + h + 20\n","    y_pct_age_center = y + h + 48\n","    y_gender_center = y + h + 75\n","    y_pct_gender_center = y + h + 103\n","\n","\n","    # Calculating bottom left corner coordinates of text based on text size and center point of background rectangle calculated above.\n","    x_age_org = int(round(x_center - (age_width / 2)))\n","    y_age_org = int(round(y_age_center + (age_height / 2)))\n","    x_pct_age_org = int(round(x_center - (pct_age_width / 2)))\n","    y_pct_age_org = int(round(y_pct_age_center + (pct_age_height / 2)))\n","    x_gender_org = int(round(x_center - (gender_width / 2)))\n","    y_gender_org = int(round(y_gender_center + (gender_height / 2)))\n","    x_pct_gender_org = int(round(x_center - (pct_age_width / 2)))\n","    y_pct_gender_org = int(round(y_pct_gender_center + (pct_gender_height / 2)))\n","\n","    face_age_background = cv2.rectangle(img, (x-1, y+h), (x+w+1, y+h+94), (200, 0, 0), cv2.FILLED)\n","    face_age_text = cv2.putText(img, age, org=(x_age_org, y_age_org), fontFace=fontFace, fontScale=age_scale, thickness=2, color=(255, 255, 255), lineType=cv2.LINE_AA)\n","    pct_age_text = cv2.putText(img, pct_age, org=(x_pct_age_org, y_pct_age_org), fontFace=fontFace, fontScale=pct_age_scale, thickness=1, color=(255, 255, 255), lineType=cv2.LINE_AA)\n","    face_gender_text = cv2.putText(img, gender, org=(x_gender_org, y_gender_org), fontFace=fontFace, fontScale=gender_scale, thickness=2, color=(255, 255, 255), lineType=cv2.LINE_AA)\n","    pct_gender_text = cv2.putText(img, pct_gender, org=(x_pct_gender_org, y_pct_gender_org), fontFace=fontFace, fontScale=pct_gender_scale, thickness=1, color=(255, 255, 255), lineType=cv2.LINE_AA)\n","\n","    return (face_age_background, face_age_text, face_gender_text)\n","\n","\n","# Defining a function to find faces in an image and then classify each found face into age-ranges defined above.\n","\n","def classify_age(img):\n","\n","    # Making a copy of the image for overlay of ages and making a grayscale copy for passing to the loaded model for age classification.\n","    img_copy = np.copy(img)\n","    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","    # Detecting faces in the image using the face_cascade loaded above and storing their coordinates into a list.\n","    faces = face_cascade.detectMultiScale(img_copy, scaleFactor=1.2, minNeighbors=6, minSize=(100, 100))\n","    # print(f\"{len(faces)} faces found.\")\n","\n","    # Looping through each face found in the image.\n","    for i, (x, y, w, h) in enumerate(faces):\n","\n","        # Drawing a rectangle around the found face.\n","        face_rect = cv2.rectangle(img_copy, (x, y), (x+w, y+h), (0, 100, 0), thickness=2)\n","        \n","        # Predicting the age of the found face using the model loaded above.\n","        x2, y2, w2, h2 = shrink_face_roi(x, y, w, h)\n","        face_roi_1 = img_copy[y2:y2+h2, x2:x2+w2]\n","        face_roi_1 = cv2.resize(face_roi_1, (224, 224))\n","        face_roi_1 = face_roi_1.reshape(-1, 224, 224, 3)\n","        face_roi_2 = img_gray[y2:y2+h2, x2:x2+w2]\n","        face_roi_2 = cv2.resize(face_roi_2, (200, 200))\n","        face_roi_2 = face_roi_2.reshape(-1, 200, 200, 1)\n","        face_age = age_ranges[np.argmax(age_model.predict(face_roi_1))]\n","        face_age_pct = f\"({round(np.max(age_model.predict(face_roi_1))*100, 2)}%)\"\n","        face_gender = gender_ranges[np.argmax(gender_model.predict(face_roi_2))]\n","        face_gender_pct = f\"({round(np.max(gender_model.predict(face_roi_2))*100, 2)}%)\"\n","        \n","        \n","        # Calling the above defined function to create the predicted age overlay on the image.\n","        face_age_background, face_age_text, face_gender_text = create_age_text(img_copy, face_age, face_age_pct, face_gender, face_gender_pct, x, y, w, h)\n","        # print(f\"Age prediction for face {i+1} : {face_age} years old\")\n","\n","    return img_copy\n","\n","\n","# Defining a function to return the image filepath with a new filename.\n","# If INPUT filepath is \"my_folder1/my_folder2/my_image.jpg\", OUTPUT filepath will be \"my_folder1/my_folder2/my_image_WITH_AGE.jpg\"\n","\n","def new_img_name(org_img_path):\n","    img_path, img_name_ext = os.path.split(org_img_path)\n","    img_name, img_ext = os.path.splitext(img_name_ext)\n","\n","    new_img_name_ext = img_name+\"_WITH_AGE\"+img_ext\n","    new_img_path = os.path.join(img_path, new_img_name_ext)\n","\n","    return new_img_path\n","\n","\n","# Defining a function to return the video filepath with a new filename.\n","# If INPUT filepath is \"my_folder1/my_folder2/my_video.mp4\", OUTPUT filepath will be \"my_folder1/my_folder2/my_video_WITH_AGE.mp4\"\n","\n","def new_vid_name(org_vid_path):\n","    vid_path, vid_name_ext = os.path.split(org_vid_path)\n","    vid_name, vid_ext = os.path.splitext(vid_name_ext)\n","\n","    new_vid_name_ext = vid_name+\"_WITH_AGE_latest\"+\".mp4\"\n","    new_vid_path = os.path.join(vid_path, new_vid_name_ext)\n","\n","    return new_vid_path"],"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wiLc7OZffY2_"},"source":["# Upload Video"]},{"cell_type":"code","metadata":{"id":"onMQZzMRiSXo","executionInfo":{"status":"ok","timestamp":1636571432263,"user_tz":-480,"elapsed":4,"user":{"displayName":"Low Feng Gabriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02805359518869888109"}}},"source":["# Define Video File\n","video = '/content/drive/MyDrive/videos/shua_video.mov'"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"En4r7fPygq9o","executionInfo":{"status":"ok","timestamp":1636573611698,"user_tz":-480,"elapsed":2179439,"user":{"displayName":"Low Feng Gabriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02805359518869888109"}},"outputId":"56b6fdd7-44b3-4f21-de0b-d7f4dde0cb2e"},"source":["# Reading the video from filepath provided above and passing it through the age clasification method defined above.\n","# Source 1: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n","# Source 2: https://www.learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/\n","\n","# Creating a VideoCapture object.\n","cap = cv2.VideoCapture(video)\n","\n","# Getting the video frame width and height.\n","frame_width = int(cap.get(3))\n","frame_height = int(cap.get(4))\n","\n","# Defining the codec and creating a VideoWriter object to save the output video at the same location.\n","fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n","new_my_video = new_vid_name(video)\n","out = cv2.VideoWriter(new_my_video, fourcc, 18, (frame_width, frame_height))\n","\n","while(cap.isOpened()):\n","    \n","    # Grabbing each individual frame, frame-by-frame.\n","    ret, frame = cap.read()\n","    \n","    if ret==True:\n","        \n","        # Running age detection on the grabbed frame.\n","        age_img = classify_age(frame)\n","        \n","        # Saving frame to output video using the VideoWriter object defined above.\n","        out.write(age_img)\n","\n","    else:\n","        break\n","\n","# Releasing the VideoCapture and VideoWriter objects.\n","cap.release()\n","out.release()\n","print(f\"Saved to {new_my_video}\")"],"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved to /content/drive/MyDrive/videos/shua_video_WITH_AGE_latest.mp4\n"]}]}]}